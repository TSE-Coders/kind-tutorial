2024-08-27 17:16:20 UTC | TRACE | INFO | (pkg/util/log/log.go:826 in func1) | Starting to load the configuration
2024-08-27 17:16:20 UTC | TRACE | INFO | (pkg/util/log/log.go:826 in func1) | Loading proxy settings
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (pkg/util/log/log.go:791 in func1) | 'use_proxy_for_cloud_metadata' is enabled: adding cloud provider URL to the no_proxy list
2024-08-27 17:16:20 UTC | TRACE | INFO | (pkg/util/log/log.go:826 in func1) | Starting to resolve secrets
2024-08-27 17:16:20 UTC | TRACE | WARN | (pkg/util/log/log.go:871 in func1) | Agent configuration relax permissions constraint on the secret backend cmd, Group can read and exec
2024-08-27 17:16:20 UTC | TRACE | INFO | (pkg/util/log/log.go:826 in func1) | Finished resolving secrets
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (pkg/util/log/log.go:786 in func1) | FIPS mode is disabled
2024-08-27 17:16:20 UTC | TRACE | INFO | (pkg/util/log/log.go:831 in func1) | 3 Features detected from environment: kubernetes,cri,containerd
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (pkg/util/log/log.go:791 in func1) | attempting to create grpc agent client connection to: localhost:5001
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (pkg/util/log/log.go:786 in func1) | grpc agent secure client created
2024-08-27 17:16:20 UTC | TRACE | INFO | (pkg/util/log/log.go:831 in func1) | Loaded configuration: /etc/datadog-agent/datadog.yaml
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (pkg/util/log/log.go:791 in func1) | Setting DefaultEnv to "kind-testing" (from `env:` entry under the 'tags' config option: "env:kind-testing")
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (pkg/util/log/log.go:791 in func1) | attempting to create grpc agent client connection to: localhost:5001
2024-08-27 17:16:20 UTC | TRACE | INFO | (pkg/util/log/log.go:831 in func1) | Could not get hostname via gRPC: context deadline exceeded. Falling back to other methods.
2024-08-27 17:16:20 UTC | TRACE | INFO | (pkg/util/log/log.go:831 in func1) | Acquired hostname from core agent (/opt/datadog-agent/bin/agent/agent): "local-worker2-ccdaniele-kind".
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (pkg/util/log/log.go:786 in func1) | Running in a container and apm_config.max_cpu_percent is not set, setting it to 0
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (pkg/util/log/log.go:786 in func1) | Running in a container and apm_config.max_memory is not set, setting it to 0
2024-08-27 17:16:20 UTC | TRACE | INFO | (/usr/local/go/src/reflect/value.go:596 in call) | TaggerClient is created, defaultTagger type:  *remote.Tagger
2024-08-27 17:16:20 UTC | TRACE | WARN | (pkg/config/model/viper.go:214 in checkKnownKey) | config key runtime_security_config.sbom.enabled is unknown
2024-08-27 17:16:20 UTC | TRACE | INFO | (comp/core/workloadmeta/workloadmeta.go:117 in func1) | workloadmeta store initialized successfully
2024-08-27 17:16:20 UTC | TRACE | INFO | (comp/core/workloadmeta/store.go:545 in func1) | workloadmeta collector "cloudfoundry-vm" could not start. error: component workloadmeta-cloudfoundry-vm is disabled: Agent is not running on CloudFoundry
2024-08-27 17:16:20 UTC | TRACE | INFO | (comp/core/workloadmeta/store.go:545 in func1) | workloadmeta collector "docker" could not start. error: component workloadmeta-docker is disabled: Agent is not running on Docker
2024-08-27 17:16:20 UTC | TRACE | INFO | (comp/core/workloadmeta/store.go:545 in func1) | workloadmeta collector "cloudfoundry-container" could not start. error: component workloadmeta-cloudfoundry-container is disabled: Agent is not running on CloudFoundry
2024-08-27 17:16:20 UTC | TRACE | INFO | (comp/core/workloadmeta/store.go:545 in func1) | workloadmeta collector "ecs" could not start. error: component workloadmeta-ecs is disabled: Agent is not running on ECS EC2
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (pkg/util/kubernetes/kubelet/kubelet_hosts.go:55 in getKubeletHostFromConfig) | Trying to parse kubernetes_kubelet_host: 172.18.0.4
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (pkg/util/kubernetes/kubelet/kubelet_hosts.go:70 in getKubeletHostFromConfig) | Parsed kubernetes_kubelet_host: 172.18.0.4 is an address: 172.18.0.4, cached, trying to resolve it to hostname
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (pkg/util/kubernetes/kubelet/kubelet_hosts.go:76 in getKubeletHostFromConfig) | kubernetes_kubelet_host: 172.18.0.4 is resolved to: [local-worker2.kind.]
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (pkg/util/kubernetes/kubelet/kubelet_hosts.go:34 in getPotentialKubeletHosts) | Got potential kubelet connection info from config, ips: [172.18.0.4], hostnames: [local-worker2.kind.]
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (pkg/util/docker/global.go:41 in GetDockerUtilWithRetrier) | Docker init error: temporary failure in dockerutil, will retry later: Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (pkg/util/kubernetes/kubelet/kubelet_hosts.go:89 in getKubeletHostFromDocker) | unable to get hostname from docker, make sure to set the kubernetes_kubelet_host option: temporary failure in dockerutil, will retry later: Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (pkg/util/kubernetes/kubelet/kubelet_hosts.go:40 in getPotentialKubeletHosts) | Got potential kubelet connection info from docker, ips: [], hostnames: []
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (pkg/util/kubernetes/kubelet/kubelet_client.go:265 in checkKubeletConnection) | Trying to reach Kubelet with scheme: https
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (pkg/util/kubernetes/kubelet/kubelet_client.go:276 in checkKubeletConnection) | Trying to reach Kubelet at: 172.18.0.4:10250
2024-08-27 17:16:20 UTC | TRACE | INFO | (comp/core/tagger/taggerimpl/remote/tagger.go:389 in func1) | tagger stream established successfully
2024-08-27 17:16:20 UTC | TRACE | INFO | (comp/core/tagger/taggerimpl/remote/tagger.go:160 in Start) | remote tagger initialized successfully
2024-08-27 17:16:20 UTC | TRACE | INFO | (pkg/util/kubernetes/kubelet/kubelet_client.go:289 in checkKubeletConnection) | Successful configuration found for Kubelet, using URL: https://172.18.0.4:10250
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (pkg/util/clusteragent/clusteragent.go:253 in GetClusterAgentEndpoint) | Identified service for the Datadog Cluster Agent: kind-datadog-cluster-agent
2024-08-27 17:16:20 UTC | TRACE | INFO | (pkg/api/security/security.go:194 in getClusterAgentAuthToken) | Using configured cluster_agent.auth_token
2024-08-27 17:16:20 UTC | TRACE | INFO | (pkg/trace/agent/agent.go:106 in NewAgent) | Starting Agent with processor trace buffer of size 0
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (pkg/trace/writer/stats.go:95 in NewStatsWriter) | Stats writer initialized (climit=20 qsize=174)
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (pkg/util/clusteragent/clusteragent.go:114 in GetClusterAgentClient) | Cluster Agent init error: temporary failure in clusterAgentClient, will retry later: "https://10.96.66.205:5005/version" is unavailable: 403 Forbidden
2024-08-27 17:16:20 UTC | TRACE | ERROR | (comp/core/workloadmeta/collectors/internal/kubemetadata/kubemetadata.go:88 in Start) | Could not initialise the communication with the cluster agent: temporary failure in clusterAgentClient, will retry later: "https://10.96.66.205:5005/version" is unavailable: 403 Forbidden
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (comp/core/workloadmeta/store.go:545 in func1) | workloadmeta collector "kube_metadata" could not start, but will retry. error: temporary failure in clusterAgentClient, will retry later: "https://10.96.66.205:5005/version" is unavailable: 403 Forbidden
2024-08-27 17:16:20 UTC | TRACE | INFO | (comp/core/workloadmeta/store.go:545 in func1) | workloadmeta collector "process-collector" could not start. error: collector process-collector is not enabled
2024-08-27 17:16:20 UTC | TRACE | INFO | (comp/core/workloadmeta/store.go:545 in func1) | workloadmeta collector "ecs_fargate" could not start. error: component workloadmeta-ecs_fargate is disabled: Agent is not running on ECS Fargate
2024-08-27 17:16:20 UTC | TRACE | INFO | (pkg/trace/api/api.go:141 in NewHTTPReceiver) | Receiver configured with 6 decoders and a timeout of 1000ms
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (pkg/util/cgroups/pid_mapper.go:81 in getPidMapper) | cgroup.procs file at: /host/sys/fs/cgroup/cgroup.procs is empty or unreadable, considering we're not running in host PID namespace, err: <nil>
2024-08-27 17:16:20 UTC | TRACE | WARN | (pkg/util/cgroups/pid_mapper.go:97 in getPidMapper) | Usage of cgroupv2 detected but the Agent does not seem to run in host cgroup namespace. Make sure to run with --cgroupns=host, some feature may not work otherwise
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (pkg/util/cgroups/pid_mapper.go:81 in getPidMapper) | cgroup.procs file at: /host/sys/fs/cgroup/cgroup.procs is empty or unreadable, considering we're not running in host PID namespace, err: <nil>
2024-08-27 17:16:20 UTC | TRACE | WARN | (pkg/util/cgroups/pid_mapper.go:97 in getPidMapper) | Usage of cgroupv2 detected but the Agent does not seem to run in host cgroup namespace. Make sure to run with --cgroupns=host, some feature may not work otherwise
2024-08-27 17:16:20 UTC | TRACE | INFO | (pkg/trace/writer/trace.go:131 in NewTraceWriter) | Trace writer initialized (climit=100 qsize=1)
2024-08-27 17:16:20 UTC | TRACE | INFO | (pkg/util/containerd/containerd_util.go:177 in connect) | Connected to containerd - Version v1.7.15/***********************************e31f1
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (pkg/util/grpc/agent_client.go:43 in getGRPCClientConn) | attempting to create grpc agent client connection to: localhost:5001
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (pkg/util/grpc/agent_client.go:76 in GetDDAgentSecureClient) | grpc agent secure client created
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (automaxprocs@v1.5.3/maxprocs/maxprocs.go:47 in log) | maxprocs: Leaving GOMAXPROCS=12: CPU quota undefined
2024-08-27 17:16:20 UTC | TRACE | INFO | (pkg/runtime/runtime.go:28 in func1) | runtime: set GOMAXPROCS to: 12
2024-08-27 17:16:20 UTC | TRACE | INFO | (comp/trace/agent/run.go:103 in runAgentSidekicks) | Trace Agent final GOMAXPROCS: 12
2024-08-27 17:16:20 UTC | TRACE | INFO | (pkg/runtime/gomemlimit_linux.go:44 in SetGoMemLimit) | Cgroup memory limit not found, doing nothing
2024-08-27 17:16:20 UTC | TRACE | INFO | (comp/trace/agent/run.go:122 in runAgentSidekicks) | GOMEMLIMIT unconstrained.
2024-08-27 17:16:20 UTC | TRACE | INFO | (comp/trace/agent/run.go:128 in runAgentSidekicks) | Trace agent running on host local-worker2-ccdaniele-kind
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (pkg/util/cgroups/pid_mapper.go:81 in getPidMapper) | cgroup.procs file at: /host/sys/fs/cgroup/cgroup.procs is empty or unreadable, considering we're not running in host PID namespace, err: <nil>
2024-08-27 17:16:20 UTC | TRACE | WARN | (pkg/util/cgroups/pid_mapper.go:97 in getPidMapper) | Usage of cgroupv2 detected but the Agent does not seem to run in host cgroup namespace. Make sure to run with --cgroupns=host, some feature may not work otherwise
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (pkg/trace/api/pipeline_stats.go:49 in pipelineStatsProxyHandler) | [pipeline_stats] Creating proxy handler
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (pkg/trace/api/pipeline_stats.go:36 in pipelineStatsEndpoints) | [pipeline_stats] Intake URL %s https://trace.agent.datadoghq.com/api/v0.1/pipeline_stats
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (pkg/trace/api/pipeline_stats.go:73 in newPipelineStatsProxy) | [pipeline_stats] Creating reverse proxy
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (pkg/util/cgroups/pid_mapper.go:81 in getPidMapper) | cgroup.procs file at: /host/sys/fs/cgroup/cgroup.procs is empty or unreadable, considering we're not running in host PID namespace, err: <nil>
2024-08-27 17:16:20 UTC | TRACE | WARN | (pkg/util/cgroups/pid_mapper.go:97 in getPidMapper) | Usage of cgroupv2 detected but the Agent does not seem to run in host cgroup namespace. Make sure to run with --cgroupns=host, some feature may not work otherwise
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (pkg/util/cgroups/pid_mapper.go:81 in getPidMapper) | cgroup.procs file at: /host/sys/fs/cgroup/cgroup.procs is empty or unreadable, considering we're not running in host PID namespace, err: <nil>
2024-08-27 17:16:20 UTC | TRACE | WARN | (pkg/util/cgroups/pid_mapper.go:97 in getPidMapper) | Usage of cgroupv2 detected but the Agent does not seem to run in host cgroup namespace. Make sure to run with --cgroupns=host, some feature may not work otherwise
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (pkg/util/cgroups/pid_mapper.go:81 in getPidMapper) | cgroup.procs file at: /host/sys/fs/cgroup/cgroup.procs is empty or unreadable, considering we're not running in host PID namespace, err: <nil>
2024-08-27 17:16:20 UTC | TRACE | WARN | (pkg/util/cgroups/pid_mapper.go:97 in getPidMapper) | Usage of cgroupv2 detected but the Agent does not seem to run in host cgroup namespace. Make sure to run with --cgroupns=host, some feature may not work otherwise
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (pkg/util/cgroups/pid_mapper.go:81 in getPidMapper) | cgroup.procs file at: /host/sys/fs/cgroup/cgroup.procs is empty or unreadable, considering we're not running in host PID namespace, err: <nil>
2024-08-27 17:16:20 UTC | TRACE | WARN | (pkg/util/cgroups/pid_mapper.go:97 in getPidMapper) | Usage of cgroupv2 detected but the Agent does not seem to run in host cgroup namespace. Make sure to run with --cgroupns=host, some feature may not work otherwise
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (pkg/util/cgroups/pid_mapper.go:81 in getPidMapper) | cgroup.procs file at: /host/sys/fs/cgroup/cgroup.procs is empty or unreadable, considering we're not running in host PID namespace, err: <nil>
2024-08-27 17:16:20 UTC | TRACE | WARN | (pkg/util/cgroups/pid_mapper.go:97 in getPidMapper) | Usage of cgroupv2 detected but the Agent does not seem to run in host cgroup namespace. Make sure to run with --cgroupns=host, some feature may not work otherwise
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (pkg/util/cgroups/pid_mapper.go:81 in getPidMapper) | cgroup.procs file at: /host/sys/fs/cgroup/cgroup.procs is empty or unreadable, considering we're not running in host PID namespace, err: <nil>
2024-08-27 17:16:20 UTC | TRACE | WARN | (pkg/util/cgroups/pid_mapper.go:97 in getPidMapper) | Usage of cgroupv2 detected but the Agent does not seem to run in host cgroup namespace. Make sure to run with --cgroupns=host, some feature may not work otherwise
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (pkg/util/cgroups/pid_mapper.go:81 in getPidMapper) | cgroup.procs file at: /host/sys/fs/cgroup/cgroup.procs is empty or unreadable, considering we're not running in host PID namespace, err: <nil>
2024-08-27 17:16:20 UTC | TRACE | WARN | (pkg/util/cgroups/pid_mapper.go:97 in getPidMapper) | Usage of cgroupv2 detected but the Agent does not seem to run in host cgroup namespace. Make sure to run with --cgroupns=host, some feature may not work otherwise
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (pkg/util/cgroups/pid_mapper.go:81 in getPidMapper) | cgroup.procs file at: /host/sys/fs/cgroup/cgroup.procs is empty or unreadable, considering we're not running in host PID namespace, err: <nil>
2024-08-27 17:16:20 UTC | TRACE | WARN | (pkg/util/cgroups/pid_mapper.go:97 in getPidMapper) | Usage of cgroupv2 detected but the Agent does not seem to run in host cgroup namespace. Make sure to run with --cgroupns=host, some feature may not work otherwise
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (pkg/util/cgroups/pid_mapper.go:81 in getPidMapper) | cgroup.procs file at: /host/sys/fs/cgroup/cgroup.procs is empty or unreadable, considering we're not running in host PID namespace, err: <nil>
2024-08-27 17:16:20 UTC | TRACE | WARN | (pkg/util/cgroups/pid_mapper.go:97 in getPidMapper) | Usage of cgroupv2 detected but the Agent does not seem to run in host cgroup namespace. Make sure to run with --cgroupns=host, some feature may not work otherwise
2024-08-27 17:16:20 UTC | TRACE | INFO | (pkg/trace/api/listener.go:41 in NewMeasuredListener) | Listener started with 1000 maximum connections.
2024-08-27 17:16:20 UTC | TRACE | INFO | (pkg/trace/api/api.go:235 in Start) | Listening for traces at http://0.0.0.0:8126
2024-08-27 17:16:20 UTC | TRACE | INFO | (pkg/trace/api/listener.go:41 in NewMeasuredListener) | Listener started with 1000 maximum connections.
2024-08-27 17:16:20 UTC | TRACE | INFO | (pkg/trace/api/api.go:253 in Start) | Listening for traces at unix:///var/run/datadog/apm.socket
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (pkg/trace/stats/concentrator.go:145 in Run) | Starting concentrator
2024-08-27 17:16:20 UTC | TRACE | INFO | (pkg/config/remote/client/client.go:389 in pollLoop) | retrying the first update of remote-config state (rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing: dial tcp [::1]:5001: connect: connection refused")
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (comp/core/workloadmeta/collectors/internal/containerd/containerd.go:302 in notifyInitialImageEvents) | 30 initial image events sent for namespace k8s.io. total number of images reference is 87
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (comp/core/workloadmeta/collectors/internal/containerd/container_builder.go:91 in buildWorkloadMetaContainer) | cannot get IP of container no running task found: task 0ab011e9f4c2afdaff2812162f8c32968a66ef52ebec40c198ac04d9e4447f3b not found: not found
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (comp/core/workloadmeta/collectors/internal/containerd/container_builder.go:91 in buildWorkloadMetaContainer) | cannot get IP of container no running task found: task 5ebb4ed14cd425a1fa5029daad82f4722bbe4d446c7b4ecaaf379173f46c976e not found: not found
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (comp/core/workloadmeta/collectors/internal/containerd/container_builder.go:91 in buildWorkloadMetaContainer) | cannot get IP of container no running task found: task 6936ab8bb2a8498a0d941fd65820ed222dcfe94cca2b84e47014bb6755f12aa6 not found: not found
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (comp/core/workloadmeta/collectors/internal/containerd/container_builder.go:91 in buildWorkloadMetaContainer) | cannot get IP of container no running task found: task 6ad2903dedea8e002e04c28b39a561c1826201755ac181367f6da8ae60c4b1d9 not found: not found
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (comp/core/workloadmeta/collectors/util/image_metadata_util.go:38 in ExtractRepoDigestFromImage) | cannot get matched registry in repodigests for image sha256:4740c1948d3fceb8d7dacc63033aa6299d80794ee4f4811539ec1081d9211f3d
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (comp/core/workloadmeta/collectors/internal/containerd/container_builder.go:67 in buildWorkloadMetaContainer) | cannot get repo digest for image sha256:4740c1948d3fceb8d7dacc63033aa6299d80794ee4f4811539ec1081d9211f3d from workloadmeta store
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (comp/core/workloadmeta/collectors/internal/containerd/container_builder.go:91 in buildWorkloadMetaContainer) | cannot get IP of container no running task found: task a1d669bc47961c47ad9fb961489252d2b6dfdd19ee0a932e2cb887e6fb937b03 not found: not found
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (comp/core/workloadmeta/collectors/internal/containerd/container_builder.go:91 in buildWorkloadMetaContainer) | cannot get IP of container no running task found: task a2785492aa383086ed217dff7feed669febb205118bb7b15d724e6bf27e670ca not found: not found
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (comp/core/workloadmeta/collectors/internal/containerd/container_builder.go:91 in buildWorkloadMetaContainer) | cannot get IP of container no running task found: task d9df99fdae999142aa1d2146a6f6d0e8ae45e811ffd6c78deae71a6fa7fc62cc not found: not found
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (comp/core/workloadmeta/collectors/internal/containerd/container_builder.go:91 in buildWorkloadMetaContainer) | cannot get IP of container no running task found: task f03d7c9baee4dca5a7ffe136e647367cfec023024ccaca6dfe3e16b4d04c6c0d not found: not found
2024-08-27 17:16:20 UTC | TRACE | INFO | (comp/core/workloadmeta/store.go:545 in func1) | workloadmeta collector "containerd" started successfully
2024-08-27 17:16:20 UTC | TRACE | INFO | (comp/core/workloadmeta/store.go:545 in func1) | workloadmeta collector "host" started successfully
2024-08-27 17:16:20 UTC | TRACE | INFO | (comp/core/workloadmeta/store.go:545 in func1) | workloadmeta collector "podman" could not start. error: component workloadmeta-podman is disabled: Podman not detected
2024-08-27 17:16:20 UTC | TRACE | INFO | (comp/core/workloadmeta/store.go:545 in func1) | workloadmeta collector "kubelet" started successfully
2024-08-27 17:16:20 UTC | TRACE | DEBUG | (pkg/util/kubernetes/kubelet/podwatcher.go:146 in computeChanges) | Found 9 changed pods out of 9
2024-08-27 17:16:21 UTC | TRACE | DEBUG | (pkg/util/clusteragent/clusteragent.go:253 in GetClusterAgentEndpoint) | Identified service for the Datadog Cluster Agent: kind-datadog-cluster-agent
2024-08-27 17:16:21 UTC | TRACE | INFO | (pkg/api/security/security.go:194 in getClusterAgentAuthToken) | Using configured cluster_agent.auth_token
2024-08-27 17:16:21 UTC | TRACE | DEBUG | (pkg/util/clusteragent/clusteragent.go:114 in GetClusterAgentClient) | Cluster Agent init error: temporary failure in clusterAgentClient, will retry later: "https://10.96.66.205:5005/version" is unavailable: 403 Forbidden
2024-08-27 17:16:21 UTC | TRACE | ERROR | (comp/core/workloadmeta/collectors/internal/kubemetadata/kubemetadata.go:88 in Start) | Could not initialise the communication with the cluster agent: temporary failure in clusterAgentClient, will retry later: "https://10.96.66.205:5005/version" is unavailable: 403 Forbidden
2024-08-27 17:16:21 UTC | TRACE | DEBUG | (comp/core/workloadmeta/store.go:545 in func1) | workloadmeta collector "kube_metadata" could not start, but will retry. error: temporary failure in clusterAgentClient, will retry later: "https://10.96.66.205:5005/version" is unavailable: 403 Forbidden
2024-08-27 17:16:23 UTC | TRACE | DEBUG | (pkg/util/clusteragent/clusteragent.go:114 in GetClusterAgentClient) | Cluster Agent init error: temporary failure in clusterAgentClient, will retry later: try delay not elapsed yet
2024-08-27 17:16:23 UTC | TRACE | ERROR | (comp/core/workloadmeta/collectors/internal/kubemetadata/kubemetadata.go:88 in Start) | Could not initialise the communication with the cluster agent: temporary failure in clusterAgentClient, will retry later: try delay not elapsed yet
2024-08-27 17:16:23 UTC | TRACE | DEBUG | (comp/core/workloadmeta/store.go:545 in func1) | workloadmeta collector "kube_metadata" could not start, but will retry. error: temporary failure in clusterAgentClient, will retry later: try delay not elapsed yet
2024-08-27 17:16:25 UTC | TRACE | DEBUG | (pkg/util/clusteragent/clusteragent.go:253 in GetClusterAgentEndpoint) | Identified service for the Datadog Cluster Agent: kind-datadog-cluster-agent
2024-08-27 17:16:25 UTC | TRACE | INFO | (pkg/api/security/security.go:194 in getClusterAgentAuthToken) | Using configured cluster_agent.auth_token
2024-08-27 17:16:25 UTC | TRACE | DEBUG | (pkg/util/clusteragent/clusteragent.go:114 in GetClusterAgentClient) | Cluster Agent init error: temporary failure in clusterAgentClient, will retry later: "https://10.96.66.205:5005/version" is unavailable: 403 Forbidden
2024-08-27 17:16:25 UTC | TRACE | ERROR | (comp/core/workloadmeta/collectors/internal/kubemetadata/kubemetadata.go:88 in Start) | Could not initialise the communication with the cluster agent: temporary failure in clusterAgentClient, will retry later: "https://10.96.66.205:5005/version" is unavailable: 403 Forbidden
2024-08-27 17:16:25 UTC | TRACE | DEBUG | (comp/core/workloadmeta/store.go:545 in func1) | workloadmeta collector "kube_metadata" could not start, but will retry. error: temporary failure in clusterAgentClient, will retry later: "https://10.96.66.205:5005/version" is unavailable: 403 Forbidden
2024-08-27 17:16:25 UTC | TRACE | DEBUG | (pkg/util/kubernetes/kubelet/podwatcher.go:146 in computeChanges) | Found 0 changed pods out of 9
2024-08-27 17:16:25 UTC | TRACE | INFO | (pkg/trace/info/stats.go:91 in LogAndResetStats) | No data received
2024-08-27 17:16:29 UTC | TRACE | DEBUG | (pkg/util/clusteragent/clusteragent.go:253 in GetClusterAgentEndpoint) | Identified service for the Datadog Cluster Agent: kind-datadog-cluster-agent
2024-08-27 17:16:29 UTC | TRACE | INFO | (pkg/api/security/security.go:194 in getClusterAgentAuthToken) | Using configured cluster_agent.auth_token
2024-08-27 17:16:29 UTC | TRACE | DEBUG | (pkg/util/clusteragent/clusteragent.go:114 in GetClusterAgentClient) | Cluster Agent init error: temporary failure in clusterAgentClient, will retry later: "https://10.96.66.205:5005/version" is unavailable: 403 Forbidden
2024-08-27 17:16:29 UTC | TRACE | ERROR | (comp/core/workloadmeta/collectors/internal/kubemetadata/kubemetadata.go:88 in Start) | Could not initialise the communication with the cluster agent: temporary failure in clusterAgentClient, will retry later: "https://10.96.66.205:5005/version" is unavailable: 403 Forbidden
2024-08-27 17:16:29 UTC | TRACE | DEBUG | (comp/core/workloadmeta/store.go:545 in func1) | workloadmeta collector "kube_metadata" could not start, but will retry. error: temporary failure in clusterAgentClient, will retry later: "https://10.96.66.205:5005/version" is unavailable: 403 Forbidden
2024-08-27 17:16:30 UTC | TRACE | DEBUG | (pkg/util/kubernetes/kubelet/podwatcher.go:146 in computeChanges) | Found 0 changed pods out of 9
2024-08-27 17:16:35 UTC | TRACE | DEBUG | (pkg/util/kubernetes/kubelet/podwatcher.go:146 in computeChanges) | Found 0 changed pods out of 9
2024-08-27 17:16:36 UTC | TRACE | DEBUG | (pkg/util/clusteragent/clusteragent.go:114 in GetClusterAgentClient) | Cluster Agent init error: temporary failure in clusterAgentClient, will retry later: try delay not elapsed yet
2024-08-27 17:16:36 UTC | TRACE | ERROR | (comp/core/workloadmeta/collectors/internal/kubemetadata/kubemetadata.go:88 in Start) | Could not initialise the communication with the cluster agent: temporary failure in clusterAgentClient, will retry later: try delay not elapsed yet
2024-08-27 17:16:36 UTC | TRACE | DEBUG | (comp/core/workloadmeta/store.go:545 in func1) | workloadmeta collector "kube_metadata" could not start, but will retry. error: temporary failure in clusterAgentClient, will retry later: try delay not elapsed yet
2024-08-27 17:16:40 UTC | TRACE | DEBUG | (pkg/util/kubernetes/kubelet/podwatcher.go:146 in computeChanges) | Found 0 changed pods out of 9
2024-08-27 17:16:40 UTC | TRACE | DEBUG | (pkg/trace/stats/concentrator.go:299 in flushNow) | Update oldestTs to 1724778990000000000
2024-08-27 17:16:42 UTC | TRACE | DEBUG | (pkg/util/clusteragent/clusteragent.go:253 in GetClusterAgentEndpoint) | Identified service for the Datadog Cluster Agent: kind-datadog-cluster-agent
2024-08-27 17:16:42 UTC | TRACE | INFO | (pkg/api/security/security.go:194 in getClusterAgentAuthToken) | Using configured cluster_agent.auth_token
2024-08-27 17:16:42 UTC | TRACE | DEBUG | (pkg/util/clusteragent/clusteragent.go:114 in GetClusterAgentClient) | Cluster Agent init error: temporary failure in clusterAgentClient, will retry later: "https://10.96.66.205:5005/version" is unavailable: 403 Forbidden
2024-08-27 17:16:42 UTC | TRACE | ERROR | (comp/core/workloadmeta/collectors/internal/kubemetadata/kubemetadata.go:88 in Start) | Could not initialise the communication with the cluster agent: temporary failure in clusterAgentClient, will retry later: "https://10.96.66.205:5005/version" is unavailable: 403 Forbidden
2024-08-27 17:16:42 UTC | TRACE | DEBUG | (comp/core/workloadmeta/store.go:545 in func1) | workloadmeta collector "kube_metadata" could not start, but will retry. error: temporary failure in clusterAgentClient, will retry later: "https://10.96.66.205:5005/version" is unavailable: 403 Forbidden
2024-08-27 17:16:44 UTC | TRACE | DEBUG | (comp/core/workloadmeta/collectors/internal/containerd/container_builder.go:91 in buildWorkloadMetaContainer) | cannot get IP of container no running task found: task a625053bc238326472b37efa5e343b0b0743dbd5358340a904cde9ab4e83c2ea not found: not found
2024-08-27 17:16:44 UTC | TRACE | DEBUG | (comp/core/workloadmeta/collectors/internal/containerd/container_builder.go:91 in buildWorkloadMetaContainer) | cannot get IP of container no running task found: task a625053bc238326472b37efa5e343b0b0743dbd5358340a904cde9ab4e83c2ea not found: not found
2024-08-27 17:16:45 UTC | TRACE | DEBUG | (pkg/util/kubernetes/kubelet/podwatcher.go:146 in computeChanges) | Found 0 changed pods out of 9
2024-08-27 17:16:50 UTC | TRACE | DEBUG | (pkg/util/kubernetes/kubelet/podwatcher.go:146 in computeChanges) | Found 1 changed pods out of 8
2024-08-27 17:16:50 UTC | TRACE | DEBUG | (pkg/trace/stats/concentrator.go:299 in flushNow) | Update oldestTs to 1724779000000000000
2024-08-27 17:16:53 UTC | TRACE | DEBUG | (pkg/util/clusteragent/clusteragent.go:114 in GetClusterAgentClient) | Cluster Agent init error: temporary failure in clusterAgentClient, will retry later: try delay not elapsed yet
2024-08-27 17:16:53 UTC | TRACE | ERROR | (comp/core/workloadmeta/collectors/internal/kubemetadata/kubemetadata.go:88 in Start) | Could not initialise the communication with the cluster agent: temporary failure in clusterAgentClient, will retry later: try delay not elapsed yet
2024-08-27 17:16:53 UTC | TRACE | DEBUG | (comp/core/workloadmeta/store.go:545 in func1) | workloadmeta collector "kube_metadata" could not start, but will retry. error: temporary failure in clusterAgentClient, will retry later: try delay not elapsed yet
2024-08-27 17:16:55 UTC | TRACE | DEBUG | (pkg/util/kubernetes/kubelet/podwatcher.go:146 in computeChanges) | Found 0 changed pods out of 8
2024-08-27 17:17:00 UTC | TRACE | DEBUG | (pkg/util/kubernetes/kubelet/podwatcher.go:146 in computeChanges) | Found 0 changed pods out of 8
2024-08-27 17:17:00 UTC | TRACE | DEBUG | (pkg/trace/stats/concentrator.go:299 in flushNow) | Update oldestTs to 1724779010000000000
2024-08-27 17:17:05 UTC | TRACE | DEBUG | (pkg/util/kubernetes/kubelet/podwatcher.go:146 in computeChanges) | Found 0 changed pods out of 8
2024-08-27 17:17:10 UTC | TRACE | DEBUG | (pkg/util/kubernetes/kubelet/podwatcher.go:146 in computeChanges) | Found 0 changed pods out of 8
2024-08-27 17:17:10 UTC | TRACE | DEBUG | (pkg/trace/stats/concentrator.go:299 in flushNow) | Update oldestTs to 1724779020000000000
2024-08-27 17:17:12 UTC | TRACE | DEBUG | (pkg/util/clusteragent/clusteragent.go:253 in GetClusterAgentEndpoint) | Identified service for the Datadog Cluster Agent: kind-datadog-cluster-agent
2024-08-27 17:17:12 UTC | TRACE | INFO | (pkg/api/security/security.go:194 in getClusterAgentAuthToken) | Using configured cluster_agent.auth_token
2024-08-27 17:17:12 UTC | TRACE | INFO | (pkg/util/clusteragent/clusteragent.go:145 in init) | Successfully connected to the Datadog Cluster Agent 7.55.2+commit.be4db09
2024-08-27 17:17:12 UTC | TRACE | INFO | (comp/core/workloadmeta/store.go:545 in func1) | workloadmeta collector "kube_metadata" started successfully
2024-08-27 17:17:15 UTC | TRACE | DEBUG | (pkg/util/kubernetes/kubelet/podwatcher.go:146 in computeChanges) | Found 0 changed pods out of 8
2024-08-27 17:17:20 UTC | TRACE | DEBUG | (pkg/util/kubernetes/kubelet/podwatcher.go:146 in computeChanges) | Found 0 changed pods out of 8
2024-08-27 17:17:20 UTC | TRACE | DEBUG | (pkg/trace/stats/concentrator.go:299 in flushNow) | Update oldestTs to 1724779030000000000
2024-08-27 17:17:25 UTC | TRACE | DEBUG | (pkg/util/kubernetes/kubelet/podwatcher.go:146 in computeChanges) | Found 0 changed pods out of 8
2024-08-27 17:17:25 UTC | TRACE | INFO | (pkg/trace/info/stats.go:91 in LogAndResetStats) | No data received
